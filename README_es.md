<div align="center">

# Aquiles-Image

<img src="https://res.cloudinary.com/dmtomxyvm/image/upload/v1763763684/aquiles_image_m6ej7u.png" alt="Aquiles-Image Logo" width="800"/>

### **Generaci√≥n de im√°genes/videos autoalojada con APIs compatibles con OpenAI**

*üöÄ FastAPI ‚Ä¢ Diffusers ‚Ä¢ Reemplazo directo de OpenAI*

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green.svg)](https://fastapi.tiangolo.com)
[![OpenAI Compatible](https://img.shields.io/badge/OpenAI-Compatible-orange.svg)](https://platform.openai.com/docs/api-reference/images)
[![PyPI Version](https://img.shields.io/pypi/v/aquiles-image.svg)](https://pypi.org/project/aquiles-image/)
[![PyPI Downloads](https://static.pepy.tech/personalized-badge/aquiles-image?period=total&units=INTERNATIONAL_SYSTEM&left_color=BLACK&right_color=MAGENTA&left_text=downloads)](https://pypi.org/project/aquiles-image/)
[![Docs](https://img.shields.io/badge/Docs-Read%20the%20Docs-brightgreen.svg)](https://aquiles-ai.github.io/aquiles-image-docs/) 
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/Aquiles-ai/Aquiles-Image)
[![View Code Wiki](https://www.gstatic.com/_/boq-sdlc-agents-ui/_/r/YUi5dj2UWvE.svg)](https://codewiki.google/github.com/aquiles-ai/aquiles-image)

[**\[ [English](README.md) | Espa√±ol \]**]

</div>

## üéØ ¬øQu√© es Aquiles-Image?

**Aquiles-Image** es un servidor de API listo para producci√≥n que te permite ejecutar modelos de generaci√≥n de im√°genes de √∫ltima generaci√≥n en tu propia infraestructura. Dise√±ado para ser compatible con OpenAI, puedes cambiar de servicios externos a autoalojado en menos de 5 minutos.

### ¬øPor qu√© Aquiles-Image?

| Desaf√≠o | Soluci√≥n de Aquiles-Image |
|---------|---------------------------|
| üí∏ **APIs externas costosas** | Ejecuta modelos localmente con uso ilimitado |
| üîí **Preocupaciones de privacidad** | Tus im√°genes nunca salen de tu servidor |
| üêå **Inferencia lenta** | Optimizaciones avanzadas para generaci√≥n 3x m√°s r√°pida |
| üîß **Configuraci√≥n compleja** | Un solo comando para ejecutar cualquier modelo compatible |
| üö´ **Dependencia del proveedor** | Compatible con OpenAI, cambia sin reescribir c√≥digo |

### Caracter√≠sticas Principales

- **üîå Compatible con OpenAI** - Usa el cliente oficial de OpenAI sin ning√∫n cambio en el c√≥digo
- **‚ö° Agrupaci√≥n Inteligente** - Agrupaci√≥n autom√°tica de solicitudes por par√°metros compartidos para m√°ximo rendimiento en configuraciones de una o m√∫ltiples GPUs
- **üé® M√°s de 30 Modelos Optimizados** - 18 de imagen (FLUX, SD3.5, Qwen) + 12 de video (Wan2.x, HunyuanVideo) + ilimitados v√≠a AutoPipeline (solo T2I)
- **üöÄ Soporte Multi-GPU** - Inferencia distribuida con balanceo de carga din√°mico entre GPUs (modelos de imagen) para escalado horizontal
- **üõ†Ô∏è Excelente Experiencia de Desarrollo** - CLI simple, modo dev para pruebas, monitoreo integrado
- **üé¨ Video Avanzado** - Texto a video con las series Wan2.x y HunyuanVideo (+ variantes Turbo)

## üöÄ Inicio R√°pido

### Instalaci√≥n

```bash
# Desde PyPI (recomendado)
pip install aquiles-image

# Desde el c√≥digo fuente
git clone https://github.com/Aquiles-ai/Aquiles-Image.git
cd Aquiles-Image
pip install .
```

### Iniciar el Servidor

**Modo de Dispositivo √önico (Por defecto)**
```bash
aquiles-image serve --model "stabilityai/stable-diffusion-3.5-medium"
```

**Modo Distribuido Multi-GPU (Solo modelos de imagen)**
```bash
aquiles-image serve --model "stabilityai/stable-diffusion-3.5-medium" --dist-inference
```

> **Nota sobre Inferencia Distribuida**: Activa el modo multi-GPU agregando la flag `--dist-inference`. Cada GPU cargar√° una copia del modelo, as√≠ que aseg√∫rate de que cada GPU tenga suficiente VRAM. El sistema balancea autom√°ticamente la carga entre GPUs y agrupa solicitudes con par√°metros compartidos para m√°ximo rendimiento.

### Genera tu Primera Imagen

```python
from openai import OpenAI

client = OpenAI(base_url="http://127.0.0.1:5500", api_key="not-needed")

result = client.images.generate(
    model="stabilityai/stable-diffusion-3.5-medium",
    prompt="a white siamese cat",
    size="1024x1024"
)

print(f"Image URL: {result.data[0].url}")
```

¬°Eso es todo! Ahora est√°s generando im√°genes con la misma API que usar√≠as con OpenAI.

## üé® Modelos Compatibles

### Texto a Imagen (`/images/generations`)

- `stabilityai/stable-diffusion-3-medium`
- `stabilityai/stable-diffusion-3.5-medium` 
- `stabilityai/stable-diffusion-3.5-large`
- `stabilityai/stable-diffusion-3.5-large-turbo`
- `black-forest-labs/FLUX.1-dev`
- `black-forest-labs/FLUX.1-schnell`
- `black-forest-labs/FLUX.1-Krea-dev`
- `black-forest-labs/FLUX.2-dev` * 
- `diffusers/FLUX.2-dev-bnb-4bit`
- `Tongyi-MAI/Z-Image-Turbo`
- `Qwen/Qwen-Image`
- `Qwen/Qwen-Image-2512`
- `black-forest-labs/FLUX.2-klein-4B`
- `black-forest-labs/FLUX.2-klein-9B`
- `zai-org/GLM-Image` - (Este modelo suele ser el m√°s lento de ejecutar en t√©rminos relativos)
- `Tongyi-MAI/Z-Image`

### Imagen a Imagen (`/images/edits`)

- `black-forest-labs/FLUX.1-Kontext-dev`
- `diffusers/FLUX.2-dev-bnb-4bit` - Soporta edici√≥n de m√∫ltiples im√°genes. M√°ximo 10 im√°genes de entrada.
- `black-forest-labs/FLUX.2-dev` * - Soporta edici√≥n de m√∫ltiples im√°genes. M√°ximo 10 im√°genes de entrada.
- `Qwen/Qwen-Image-Edit` 
- `Qwen/Qwen-Image-Edit-2509` - Soporta edici√≥n de m√∫ltiples im√°genes. M√°ximo 3 im√°genes de entrada.
- `Qwen/Qwen-Image-Edit-2511` - Soporta edici√≥n de m√∫ltiples im√°genes. M√°ximo 3 im√°genes de entrada.
- `black-forest-labs/FLUX.2-klein-4B` - Soporta edici√≥n de m√∫ltiples im√°genes. M√°ximo 10 im√°genes de entrada.
- `black-forest-labs/FLUX.2-klein-9B` - Soporta edici√≥n de m√∫ltiples im√°genes. M√°ximo 10 im√°genes de entrada.
- `zai-org/GLM-Image` - Soporta edici√≥n de m√∫ltiples im√°genes. M√°ximo 5 im√°genes de entrada. (Este modelo suele ser el m√°s lento de ejecutar en t√©rminos relativos)

> **\* Nota sobre FLUX.2-dev**: Requiere NVIDIA H200.

### Texto a Video (`/videos`)

#### Serie Wan2.2
- `Wan-AI/Wan2.2-T2V-A14B` (Alta calidad, 40 pasos - inicia con `--model "wan2.2"`)
- `Aquiles-ai/Wan2.2-Turbo` ‚ö° **9.5x m√°s r√°pido** - ¬°La misma calidad en 4 pasos! (inicia con `--model "wan2.2-turbo"`)

#### Serie Wan2.1
- `Wan-AI/Wan2.1-T2V-14B` (Alta calidad, 40 pasos - inicia con `--model "wan2.1"`)
- `Aquiles-ai/Wan2.1-Turbo` ‚ö° **9.5x m√°s r√°pido** - ¬°La misma calidad en 4 pasos! (inicia con `--model "wan2.1-turbo"`)
- `Wan-AI/Wan2.1-T2V-1.3B` (Versi√≥n ligera, 40 pasos - inicia con `--model "wan2.1-3B"`)
- `Aquiles-ai/Wan2.1-Turbo-fp8` ‚ö° **9.5x m√°s r√°pido + optimizado FP8** - 4 pasos (inicia con `--model "wan2.1-turbo-fp8"`)

#### Serie HunyuanVideo-1.5

**Resoluci√≥n Est√°ndar (480p)**
- `Aquiles-ai/HunyuanVideo-1.5-480p` (50 pasos - inicia con `--model "hunyuanVideo-1.5-480p"`)
- `Aquiles-ai/HunyuanVideo-1.5-480p-fp8` (50 pasos, optimizado FP8 - inicia con `--model "hunyuanVideo-1.5-480p-fp8"`)
- `Aquiles-ai/HunyuanVideo-1.5-480p-Turbo` ‚ö° **12.5x m√°s r√°pido** - ¬°4 pasos! (inicia con `--model "hunyuanVideo-1.5-480p-turbo"`)
- `Aquiles-ai/HunyuanVideo-1.5-480p-Turbo-fp8` ‚ö° **12.5x m√°s r√°pido + optimizado FP8** - 4 pasos (inicia con `--model "hunyuanVideo-1.5-480p-turbo-fp8"`)

**Alta Resoluci√≥n (720p)**
- `Aquiles-ai/HunyuanVideo-1.5-720p` (50 pasos - inicia con `--model "hunyuanVideo-1.5-720p"`)
- `Aquiles-ai/HunyuanVideo-1.5-720p-fp8` (50 pasos, optimizado FP8 - inicia con `--model "hunyuanVideo-1.5-720p-fp8"`)

#### LTX-2 (Generaci√≥n Audio-Visual Conjunta - Experimental)

- `Lightricks/ltx-2-19b-dev` (40 pasos - inicia con `--model "ltx-2"`)

> **Caracter√≠sticas Especiales**: LTX-2 es el primer modelo de **c√≥digo abierto** que soporta generaci√≥n sincronizada de audio y video en un solo modelo, comparable a modelos cerrados como [Sora-2](https://openai.com/index/sora-2/) y [Veo 3.1](https://gemini.google/cl/overview/video-generation/). Para mejores resultados con este modelo, sigue la [gu√≠a de prompts](https://ltx.io/model/model-blog/prompting-guide-for-ltx-2) proporcionada por el equipo de Lightricks.

> **Requisitos de VRAM**: La mayor√≠a de los modelos necesitan 24GB+ de VRAM. Todos los modelos de video requieren H100/A100-80GB. Las versiones optimizadas con FP8 ofrecen mejor eficiencia de memoria.

[**üìñ Documentaci√≥n completa de modelos**](https://aquiles-ai.github.io/aquiles-image-docs/#models) y m√°s modelos en [**üé¨ Aquiles-Studio**](https://huggingface.co/collections/Aquiles-ai/aquiles-studio)

## üí° Ejemplos

### Generando Im√°genes

https://github.com/user-attachments/assets/00e18988-0472-4171-8716-dc81b53dcafa

https://github.com/user-attachments/assets/00d4235c-e49c-435e-a71a-72c36040a8d7

### Editando Im√°genes

<div align="center">

| Entrada + Prompt | Resultado |
|------------------|-----------|
| <img src="https://res.cloudinary.com/dmtomxyvm/image/upload/v1764807968/Captura_de_pantalla_1991_as3v28.png" alt="Script de Edici√≥n" width="500"/> | <img src="https://res.cloudinary.com/dmtomxyvm/image/upload/v1764807952/Captura_de_pantalla_1994_ffmko2.png" alt="Resultado de Edici√≥n" width="500"/> |

</div>

### Generando Videos

https://github.com/user-attachments/assets/7b1270c3-b77b-48df-a0fe-ac39b2320143

> **Nota**: La generaci√≥n de video con `wan2.2` tarda ~30 minutos en H100. ¬°Con `wan2.2-turbo`, solo tarda ~3 minutos! Solo se puede generar un video a la vez.

**Generaci√≥n de video y audio**

https://github.com/user-attachments/assets/b7104dc3-5306-4e6a-97e5-93a6c1e73f54

## üß™ Funcionalidades Avanzadas

### AutoPipeline - Ejecuta Cualquier Modelo de Diffusers

Ejecuta cualquier modelo compatible con `AutoPipelineForText2Image` de HuggingFace:

```bash
aquiles-image serve \
  --model "stabilityai/stable-diffusion-xl-base-1.0" \
  --auto-pipeline \
  --set-steps 30
```

**Los modelos compatibles incluyen:**
- `stable-diffusion-v1-5/stable-diffusion-v1-5`
- `stabilityai/stable-diffusion-xl-base-1.0`
- Cualquier modelo de HuggingFace compatible con `AutoPipelineForText2Image`

**Limitaciones:**
- ‚ö†Ô∏è Inferencia m√°s lenta que las implementaciones nativas
- ‚ö†Ô∏è Sin soporte para LoRA ni adaptadores
- ‚ö†Ô∏è Experimental - puede tener problemas de estabilidad

### Modo Dev - Prueba Sin Cargar Modelos

Perfecto para desarrollo, pruebas y CI/CD:

```bash
aquiles-image serve --no-load-model
```

**Qu√© hace:**
- Inicia el servidor instant√°neamente sin GPU
- Devuelve im√°genes de prueba que simulan respuestas reales
- Todos los endpoints funcionales con formatos realistas
- Misma estructura de API que en producci√≥n

## üìä Monitoreo y Estad√≠sticas

Aquiles-Image proporciona un endpoint personalizado `/stats` para monitoreo en tiempo real:

```python
import requests

# Obtener estad√≠sticas del servidor
stats = requests.get("http://localhost:5500/stats", 
                    headers={"Authorization": "Bearer YOUR_API_KEY"}).json()

print(f"Total requests: {stats['total_requests']}")
print(f"Total images generated: {stats['total_images']}")
print(f"Queued: {stats['queued']}")
print(f"Completed: {stats['completed']}")
```

### Formatos de Respuesta

La respuesta var√≠a seg√∫n el tipo de modelo y la configuraci√≥n:

#### Modelos de Imagen - Modo Dispositivo √önico

```json
{
  "mode": "single-device",
  "total_requests": 150,
  "total_batches": 42,
  "total_images": 180,
  "queued": 3,
  "completed": 147,
  "failed": 0,
  "processing": true,
  "available": false
}
```

#### Modelos de Imagen - Modo Distribuido (Multi-GPU)

```json
{
  "mode": "distributed",
  "devices": {
    "cuda:0": {
      "id": "cuda:0",
      "available": true,
      "processing": false,
      "can_accept_batch": true,
      "batch_size": 4,
      "max_batch_size": 8,
      "images_processing": 0,
      "images_completed": 45,
      "total_batches_processed": 12,
      "avg_batch_time": 2.5,
      "estimated_load": 0.3,
      "error_count": 0,
      "last_error": null
    },
    "cuda:1": {
      "id": "cuda:1",
      "available": true,
      "processing": true,
      "can_accept_batch": false,
      "batch_size": 2,
      "max_batch_size": 8,
      "images_processing": 2,
      "images_completed": 38,
      "total_batches_processed": 10,
      "avg_batch_time": 2.8,
      "estimated_load": 0.7,
      "error_count": 0,
      "last_error": null
    }
  },
  "global": {
    "total_requests": 150,
    "total_batches": 42,
    "total_images": 180,
    "queued": 3,
    "active_batches": 1,
    "completed": 147,
    "failed": 0,
    "processing": true
  }
}
```

#### Modelos de Video

```json
{
  "total_tasks": 25,
  "queued": 2,
  "processing": 1,
  "completed": 20,
  "failed": 2,
  "available": false,
  "max_concurrent": 1
}
```

**M√©tricas Clave:**
- `total_requests/tasks` - N√∫mero total de solicitudes de generaci√≥n recibidas
- `total_images` - Total de im√°genes generadas (solo modelos de imagen)
- `queued` - Solicitudes en espera de ser procesadas
- `processing` - Solicitudes en procesamiento actualmente
- `completed` - Solicitudes completadas con √©xito
- `failed` - Solicitudes fallidas
- `available` - Si el servidor puede aceptar nuevas solicitudes
- `mode` - Modo de operaci√≥n para modelos de imagen: `single-device` o `distributed`

## üéØ Casos de Uso

| Qui√©n | Qu√© |
|-------|-----|
| üöÄ **Startups de IA** | Construye funciones de generaci√≥n de im√°genes sin costos de API |
| üë®‚Äçüíª **Desarrolladores** | Prototipa con m√∫ltiples modelos usando una sola interfaz |
| üè¢ **Empresas** | Infraestructura de IA de im√°genes escalable y privada |
| üî¨ **Investigadores** | Experimenta f√°cilmente con modelos de vanguardia |


## üìã Requisitos Previos

- Python 3.8+
- GPU compatible con CUDA y 24GB+ de VRAM (mayor√≠a de modelos)
- 10GB+ de espacio libre en disco


## üìö Documentaci√≥n

- [**Documentaci√≥n Completa**](https://aquiles-ai.github.io/aquiles-image-docs/)
- [**Referencia del Cliente**](https://aquiles-ai.github.io/aquiles-image-docs/#client-api)
- [**Gu√≠a de Modelos**](https://aquiles-ai.github.io/aquiles-image-docs/#models)

## ü§ù Contribuciones

¬°Damos la bienvenida a las contribuciones! Ya sea que quieras:
- üêõ Reportar errores y problemas
- üé® Agregar soporte para nuevos modelos de imagen
- üìù Mejorar la documentaci√≥n

Por favor lee nuestra [**Gu√≠a de Contribuci√≥n**](CONTRIBUTING.md) para comenzar.

<div align="center">

**[‚≠ê Dale una estrella al proyecto](https://github.com/Aquiles-ai/Aquiles-Image)** ‚Ä¢ **[üêõ Reportar problemas](https://github.com/Aquiles-ai/Aquiles-Image/issues)** ‚Ä¢ **[ü§ù Contribuir](CONTRIBUTING.md)**

*Construido con ‚ù§Ô∏è para la comunidad de IA*

</div>